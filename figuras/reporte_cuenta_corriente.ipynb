{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte de pronósticos de series de tiempo para cuenta corriente\n",
    "\n",
    "Este reporte tiene como objeto describir el proceso de creación de modelos econométricos y de redes neuronales usados para pronosticar las siguientes series:\n",
    "\n",
    "- IGAE\n",
    "- Remesas\n",
    "- Tipo de cambio peso-dólar \n",
    "- Inversión fija bruta\n",
    "- Inflación en México\n",
    "- Ingresos tributarios en México\n",
    "- Subsidios del gobierno federal\n",
    "- Salarios reales en México\n",
    "- Tasa de fondeo en México\n",
    "- Producción industrial en EEUU\n",
    "- Construcción en EEUU\n",
    "- Producción manufacturera en EEUU\n",
    "- Nómina no agrícola en EEUU\n",
    "- Inflación en EEUU \n",
    "- Cuenta corriente MX\n",
    "\n",
    "Lo anterior se realizó con el objetivode pronosticar la serie de cuenta corriente en México. Dado que las cifras de cuenta corriente se encuentran en constante revisión que puede durar incluso varios años, es necesario guardar las cifras con las que se realizaron los pronósticos, ya que éstas pueden cambiar abruptamente. \n",
    "\n",
    "## Análisis exploratorio de datos (EDA)\n",
    "\n",
    "Se observa que la cuenta de crédito de la cuenta corriente más grande proviene de la cuenta de bienes, la cual comprenden exportaciones de mercancías y asciende a más de 175 mil millones de pesos. Por su parte, la segunda cuenta más grande (aunque considerablemente más chica que la cuenta de bienes) es la cuenta de ingresos secundarios, los cuales son casi su totalidad ingresos por remesas y ascienden a poco menos de 23 mil millones de pesos. \n",
    "\n",
    "![](./figuras/CC_credito.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Por su parte, la cuenta de servicios primarios de crédito comprende utilidades, dividendos, intereses y remuneración de empleados, y ascendió a poco menos de 23 mil millones de pesos. Por otro lado, las de servicios suman transporte, viajes, servicios empresariales, propiedad intelectual entre los más importantes. \n",
    "\n",
    "No obstante, en saldos netos (débito - crédito) la cuenta corriente de bienes, servicios e ingresos primarios se encuentra en saldos positivos, mientras que sólo la cuenta de ingresos secundarios se encuentra en saldos negativos. Por otro lado, se observa un poco de estacionalidad en las cuentas de ingresos primarios e ingresos secundarios.\n",
    "\n",
    "![](./figuras/CC_saldosnetos.pdf)\n",
    "\n",
    "## Selección de variables explicativas\n",
    "\n",
    "Dado que en la cuenta de crédito los bienes fueron la subcuenta más grande con 178 mil millones de dólares, se revisó el análisis de exportaciones e importaciones del [atlas de Harvard](https://atlas.cid.harvard.edu/countries/138/export-basket) para México. De acuerdo con dicha base de datos, las principales *exportaciones netas* para México en 2021 fueron en autos y autopartes (~28%), computadoras (~14%), petróleo (~8.3%), otros minerales (~8.5%), así como alimentos, bebidas y agropecuarios (~8%), entre otros. \n",
    "\n",
    "Por otro lado, las cuentas de ingresos secundarios  también incluyen los ingresos por remesas, así como para la cuenta de servicios se incluyeron turismo, propiedad intelectual, que son los principales componentes.\n",
    "\n",
    "Por todo lo anterior, se incluyeron en el modelo las siguientes variables:\n",
    "\n",
    "* IGAE base 2013, serie original, mensual, publicada por INEGI.\n",
    "* Ingresos por remesas en millones de dólares, mensual, publicada por Banco de México.\n",
    "* Tipo de cambio peso-dólar promedio FIX mensual, publicada por banco de México.\n",
    "* Indice de volumen de la inversión fija bruta, publicado por el INEGI.\n",
    "* INPC general, publicado por el INEGI.\n",
    "\n",
    "![](./figuras/explicativas.png)\n",
    "Adicionalmente, se incluyeron variables de producción industrial y de inflación de EEUU, debido a la fuerte relación que tienen estas dos variables sobre los regresores usados en el modelo.\n",
    "\n",
    "Por otro lado, se incluyeron en los modelos iniciales como insumo para el tensor de convoluciones los rezagos que resultaron estadísticamente significativos en los diagramas de correlación cruzada que se muestran a continuación.\n",
    "\n",
    "![](./figuras/crosscorr.png)\n",
    "\n",
    "# Resumen de procedimiento de obtención de modelos\n",
    "\n",
    "Para la estimación con modelos de redes neuronales RNN y LSTM se realizó el siguiente procedimiento:\n",
    "\n",
    "1. Se dividió la muestra de entrenamiento en 90% y validación en 10% con orden temporal (es decir, de manera no aleatoria).\n",
    "2. Se inició con modelos auto-arima sin regresores para las siguientes variables explicativas: IGAE, remesas, tipo de cambio, inversión fija bruta, INPC, tasa de fondeo, producción industrial de EEUU, nómina no agrícola de EEUU. y cuenta corriente\n",
    "3. se incluyeron rezagos de variables explicativas estadísticamente significativos\n",
    "4. Se calcularon modelos adicionales con regresores de las variables anteriormente mencionadas.\n",
    "5. De los modelos mencionados en el inciso 2 y 3, se seleccionaron los modelos con menor RMSE.\n",
    "6. Se utilizaron los modelos del inciso 5 para crear el tensor de convoluciones de variables explicativas para las redes\n",
    "7. Se estimaron modelos de redes neuronales RNN y LSTM para cuenta corriente\n",
    "8. Se compararon RMSE entre los modelos de cuenta corriente (auto-arima, RNN y LSTM)\n",
    "\n",
    "\\newpage\n",
    "# Modelos para pronosticar la cuenta corriente.\n",
    "\n",
    "En este reporte, se utilizaron dos tipos de modelos de pronóstico de series de tiempo: los modelos ARIMA y los modelos de redes neuronales recurrentes (RNN en inglés) y de memoria de corto y largo plazo (LSTM en inglés). Si bien los modelos ARIMA tuvieron un mejor desempeño en la métrica seleccionada RMSE (*root mean squared error* en inglés, raíz de error cuadrático medio) en términos relativos, en términos absolutos las tres metodologías tuvieron un buen desempeño.\n",
    "\n",
    "#### Resumen de RMSE por modelo\n",
    "|IGAE     (ARIMA)   |Remesas    (ARIMA)    |USDMXN (ARIMA)  |Inversión FB  (ARIMA) |INPC     (ARIMA)    |Cuenta corriente (ARIMA)|Cuenta corriente (RNN) |Cuenta corriente (LSTM)|\n",
    "|-------|-----------|-----|---------|--------|-------|--------|------|\n",
    "|0.029|\t0.066|0.045\t|0.100|\t0.034|\t0.924|\t1.209|\t1.215|\n",
    "\n",
    "### Modelos ARIMA\n",
    "\n",
    "Los modelos auto regresivos de media móvil son de los modelos a los que economistas e incluso científicos de datos suelen recurrir para pronosticar series de tiempo. Si bien existen otros modelos econométricos más sofisticados y con mayor sustento teórico para ciertas variables, los modelos ARIMA son modelos altamente compatibles con las nuevas propuestas metodológicas de aprendizaje profundo, particularmente de redes neuronales. \n",
    "\n",
    "Dado que las redes neuronales piden pronósticos de los regresores para llevar a cabo el modelo, se parten de los pronósticos generados por los modelos ARIMA para tener una base explicativa para las redes neuronales. \n",
    "\n",
    "![](./figuras/arima.png)\n",
    "\n",
    "### Modelos de redes neuronales\n",
    "\n",
    "Los modelos de redes neuronales son frecuentemente utilizados en aprendizaje de máquina para variables que tienen cierta relación temporal. En este trabajo, en ambos modelos (RNN y LSTM) se utilizaron capas de perceptrones que aplican una función no lineal a una combinación lineal de los resultados en la capa anterior (o bien, en el caso de la primera capa, de la matriz de insumos). \n",
    "\n",
    "En ambos modelos, la separación entre entrenamiento y validación no fue aleatorio, al tratarse de una serie de tiempo. De haberlo hecho, erróneamente, el conjunto de entrenamiento hubiera estado contaminado con los datos que tenía como objetivo predecir. Dado que en una serie de tiempo el orden en el que se presentan los datos tiene un significado temporal, el periodo de validación debe consistir en datos que aún no han sido observados por el modelo.\n",
    "\n",
    "Por otro lado, la matriz de las variables es una matriz relativamente pequeña, por lo que en general se eligieron hiperparámetros de magnitudes relativamente pequeñas.\n",
    "\n",
    "### Redes neuronales recurrentes (RNN en inglés)\n",
    "\n",
    "En resumen, el modelo que arrojó un menor RMSE fue el siguiente: \n",
    "\n",
    "| Capas (tipo)|Dimensión de salida|Param #|   \n",
    "|------------|--------------|------------|\n",
    "|simple_rnn (SimpleRNN)|(N, 32)|1216|\n",
    "|dense (Dense)|(N,128)|4224|      \n",
    "|dense_1 (Dense)| (N,128)|16512|     \n",
    "|dense_2 (Dense)|(N,64)|8256|      \n",
    "|dense_3 (Dense) |(N,1)|65|     \n",
    "\n",
    "Núm. de parámetros (todos entrenables): 30273.\n",
    "\n",
    "Destacan las siguientes justificaciones: \n",
    "\n",
    "- 4 capas: dado que la matriz de series de tiempo es una matriz relativamente sencilla en comparación con otras aplicaciones en redes como detección de imágenes o video, los cuales suelen tener mayor dimensionalidad, se decidió usar un número bajo de capas. De inicio se iban a usar 3 capas, pero se observó que una cuarta capa mejoraba considerablemente el resultado.\n",
    "\n",
    "-número de neuronas: se buscó que el número de neuronas fueran creciendo o decreciendo gradualmente (en potencia de 2) hasta llegar a la dimensión del insumo o del producto. La convención de varios académicos es utilizar 32, 64 o 128 neuronas en cada capa, dependiendo de la naturaleza de los datos.\n",
    "\n",
    "- activaciones: sigmoide. Dado que se optó por usar un min-max scaler para que la magnitud de ciertas explicativas no sesgara al modelo, el rango de todas las variables quedó entre cero y uno, por lo que una transformación sigmoide hacía mucho sentido. No obstante, destacó que tanto en el modelo RNN como el LSTM se hizo presente el fenómeno *vanishing gradient* en la variable objetivo, ya que las colas izquierdas o derechas las subestimaba. Esto también pudo haber sido contribuido por el escalador. No obstante, remover el escalador resultaba perjudicial para el RMSE del modelo, por lo que se optó dejarlo a pesar de este inconveniente.\n",
    "\n",
    "- 120 épocas: se encontró que aumentar el número de épocas a 120 mejoraba. Las épocas van utilizando los pesos de la época precedente (de inicio los pesos son aleatorios) y se van ajustando conforme al gradiente del error de la nueva época hasta finalizar el número de épocas elegido por el usuario. Cuando se seleccionaban 120 épocas, el RMSE de entrenamiento ya no bajaba más, pero tampoco llevaba tantas épocas de haber alcanzado su estado estable. \n",
    "\n",
    "- Para el tensor de la recursión, se utilizaron cuatro periodos de ajuste (rezagos), los cuales tienen sentido al ser la cuenta corriente una serie trimestral, con factores estacionales encontrados en los modelos ARIMA. Se probó con 4, 6 y 12 periodos de ajuste, siendo 4 periodos de ajuste el modelo que arrojaba menor RMSE. Nota: las recursiones son convoluciones de la matriz de variables explicativas (suma ponderada de rezagos) y convoluciones de los rezagos de la variable objetivo. \n",
    "\n",
    "![](./figuras/modelo_RNN.pdf)\n",
    "\n",
    "### Modelos LSTM\n",
    "\n",
    "El resumen del modelo LSTM que arrojó mejores resultados en RMSE fue el siguiente: \n",
    "\n",
    "| Capas (tipo)|Dimensión de salida|Param #|   \n",
    "|------------|--------------|------------|\n",
    "|lstm (LSTM) |(N, 32) | 4864  |    \n",
    "|dense_4 (Dense)|(N, 64) |2112 |     \n",
    "|dense_5 (Dense)|(N, 128) |  8320   |   \n",
    "|dense_6 (Dense) |(N, 64) |8256|\n",
    "|leaky_re_lu (LeakyReLU) | (N, 64)|0 |\n",
    "|dense_7 (Dense)|(N, 1)| 65 |\n",
    "                                                                \n",
    "Núm. params: 23617 (todos entrenables)\n",
    "\n",
    "![](./figuras/modelo_LSTM.pdf)\n",
    "\n",
    "\\newpage\n",
    "# Explicación de metodología\n",
    "\n",
    "En general, una red neuronal es un conjunto de capas compuestas por nodos o perceptrones. Dichos perceptrones forman una combinación lineal con pesos iniciados al azar (posteriormente entrenados); a esta combinación se le aplica una transformación no lineal. Dicha transformación a su vez se vuelve insumo para entrenar a la siguiente capa. \n",
    "\n",
    "El proceso de entrenamiento (a grandes rasgos) de una red neuronal consiste en lo siguiente:\n",
    "\n",
    "1. Los pesos se inician al azar.\n",
    "2. Conforme se le van aplicando transformaciones de capas o épocas  anteriores, el modelo va evaluando su predicción con los datos reales.\n",
    "3. El error resultante se usa para ajustar los pesos iniciados al azar, con un factor de ajuste.\n",
    "4. Esos nuevos pesos se usan en una nueva época.\n",
    "5. Se vuelve a predecir el error para volver a ajustar los pesos para la época siguiente.\n",
    "\n",
    "Lo anterior se explica en el siguiente pseudocódigo (Román, 2023).\n",
    "\n",
    "![](./figuras/pseudocodigo_descenso.png)\n",
    "\n",
    "Dicha metodología tiene ventajas y desventajas. La principal ventaja es poder entrenar un modelo que sería imposible entrenar sin computadora (el número de pesos (parámetros) a entrenar pueden ser varios cientos de miles), aunque algunas deventajas son que pueden haber puntos silla, atorarse en un mínimo local, tener un factor de ajuste insuficiente o no percibir cambios en el límite de su dominio. \n",
    "\n",
    "### RNN\n",
    "\n",
    "Considérese el siguiente diagrama (Román, 2023):\n",
    "\n",
    "![](./figuras/rnn_teoria.png)\n",
    "Se observa que en las redes neuronales recurrentes, se aplica una transformación no lineal a la (en este caso) matriz de recurrencia (la combinación lineal entre los rezagos de las explicativas y los rezagos de la vairable objetivo o del producto de la capa anterior).\n",
    "\n",
    "Si la recursión es many-to-many, el producto tanto se pasará a la siguiente capa como se guardará como producto final. En el caso de este estudio no es así, sino many-to-one: sólo tenemos una variable objetivo, pero tenemos varias variables explicativas, por lo que el producto de cada capa no se guarda como producto, sino se usa como insumo de la siguiente capa.\n",
    "\n",
    "### LSTM\n",
    "\n",
    "Considérese el siguiente diagrama (Román, 2023):\n",
    "\n",
    "![](./figuras/LSTM_teoria.png)\n",
    "La descripción es la siguiente: tenemos la transformación de insumo, de olvido y de salida, todas en recurrencias (es decir, convoluciones de la variable objetivo y de las variables explicativas). A la transformación de insumo se le multiplica otra transformación de tangente hiperbólica de una recurrencia; la transformación de olvido es multiplicada por la transformación anterior y el resultado se multiplica point-wise a la recurrencia de salida. Esta multiplicación es considerada como el producto que se usará en las recurrencias de la capa siguiente.\n",
    "\n",
    "Entonces, la interpretación es la siguiente: los pesos de salida no ven las transformaciones hiperbólicas, mientras que las de entrada son generadas en esa misma capa. Conforme van avanzando el número de capas, la transformación de olvido va recopilando información generada en esa capa e información generada en capas anteriores. Lo anterior implica que va a haber información preponderantemente de las capas más recientes; el efecto de la capa contemporánea sobre el siguiente producto será mayor. \n",
    "\n",
    "El hecho de que algunos pesos estén sujetos a más transformaciones que otros implica que las variables explicativas, pesos e hiperparámetros tendrán distinta incidencia. Se observa que las explicativas se usan en todas las capas y en todas las transformaciones, por lo que implica que todos los pesos, aunque tengan más o menos transformaciones, aunque se disipen en el tiempo, tendrán muy presentes a las explicativas. Por otro lado, el efecto del tiempo mayor al rezago uno es indirecto y dado que se aplican varias transformaciones de tangente hiperbólica, se puede desvanecer, lo cual podría explicar su desventaja respecto de los modelos autorregresivos.\n",
    "\n",
    "En otras palabras, se observa que LSTM es una red de redes. Las transformaciones de entrada, de olvido y de salida tienen la misma fórmula que las redes neuronales recurrentes, con diferentes transformaciones. Por ello LSTM es un modelo más sofisticado que RNN.\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- IBM, *What are neural networks?*, 2022, (https://www.ibm.com/topics/neural-networks#:~:text=Neural%20networks%2C%20also%20known%20as,neurons%20signal%20to%20one%20another).\n",
    "\n",
    "- Román, Edgar, *Recurrent Neural Networks, deep learning*, Instituto Tecnológico Autónomo de México, Department of Computer Science, 2023.\n",
    "\n",
    "- Román, Edgar, *MLP - Backprop*, Instituto Tecnológico Autónomo de México, Department of Computer Science, 2023.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NO agobiarme con modelos\n",
    "LSTM quitarlo de gráficas, para reporte si, para su programa no \n",
    "insertar en pagina web y dejarlo lo mas automatico posible\n",
    "que estimen todos los modelos y se actualicen los pronósticos\n",
    "quese actualice dato nuevo\n",
    "dejarlo automatizado\n",
    "en pagina web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Jan/2024 19:40:07] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from flask import Flask, flash, request, redirect, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "UPLOAD_FOLDER = '/'\n",
    "ALLOWED_EXTENSIONS = {'csv'}\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        if file:\n",
    "            filename = secure_filename(file.filename)\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "            return redirect(url_for('download_file', name=filename))\n",
    "    return '''\n",
    "    <!doctype html>\n",
    "    <title>Pronósticos de series de tiempo</title>\n",
    "    <h1>Página para pronosticar series de tiempo mediante ARIMA sin regresores, ARIMA con regresores y RNN</h1>\n",
    "    <form method=post enctype=multipart/form-data>\n",
    "      <input type=file name=file>\n",
    "      <input type=submit value=Upload>\n",
    "    </form>\n",
    "    '''\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
